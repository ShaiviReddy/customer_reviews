# -*- coding: utf-8 -*-
"""sentiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j3t_K7_Mx57gM7jSgs9HZgRD_u428uz0
"""

!pip install transformers
!pip install torch

import torch
from transformers import BertTokenizer, BertForSequenceClassification
from torch.nn.functional import softmax
import matplotlib.pyplot as plt


model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'  # Pretrained model for sentiment analysis
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(model_name)


def sentiment_analysis(input_text):

    inputs = tokenizer(input_text, return_tensors="pt", truncation=True, padding=True, max_length=512)


    with torch.no_grad():
        outputs = model(**inputs)


    probs = softmax(outputs.logits, dim=-1)

    predicted_label = torch.argmax(probs, dim=-1).item()

    sentiment_labels = ['very negative', 'negative', 'neutral', 'positive', 'very positive']
    sentiment = sentiment_labels[predicted_label]

    return sentiment, probs

user_input = input("Enter a sentence for sentiment analysis: ")

sentiment, probabilities = sentiment_analysis(user_input)

print(f"Sentiment: {sentiment}")


labels = ['very negative', 'negative', 'neutral', 'positive', 'very positive']
probabilities = probabilities.squeeze().tolist()

plt.bar(labels, probabilities, color='skyblue')
plt.xlabel('Sentiment Labels')
plt.ylabel('Probability')
plt.title('Sentiment Analysis Probability Distribution')
plt.show()